# ğŸ”— Chain of Retrieval: Multi-Aspect Iterative Search Expansion and Post-Order Search Aggregation for Full Paper Retrieval

> *Multi-aspect-guided iterative retrieval framework using full context of scientific papers*

<p align="center">
  <img src="" width="650">
</p>

---

## ğŸ“˜ Overview

**Chain-of-Retrieval (CoR)** is a multi-agent retrieval framework that decomposes a full scientific paper into multiple research aspects â€” such as *methodology, research questions(motivations), and experimental results* â€” and performs retrieval via a **chain-of-query** process, while the retrieved results are then hierarchically aggregated to form robust interpretation of dynamic relations between pool of related research by taking the decaying semantic relations with retrieval depth increase.

ğŸ”— **arXiv:** [arxiv.org/abs/2507.10057](https://arxiv.org/abs/2507.10057)  
ğŸ“Š **Benchmark:** [SciFullBench/PatentFullBench](https://huggingface.co/datasets/Jackson0018/Paper2PaperRetrievalBench)

---

## ğŸš€ Setup & Usage

### ğŸ§© Environment Setup
```bash
git clone https://github.com/psw0021/Chain-of-Retrieval.git
cd Chain-of-Retrieval
conda env create -f environment.yml -n paper_retrieval
conda activate paper_retrieval
```

### ğŸ“Š Download Benchmark
```bash
python download_benchmark.py
unzip Paper2PaperRetrieval.zip -d .
```

### ğŸ¤– Download Query Optimizers
We release several **DPO-trained query optimizer LLMs** fine-tuned for scientific document retrieval tasks using **Llama-3.2-3B-Instruct** and **Qwen-2.5-3B-Instruct** backbones.  
Each model is trained with different embedding backends (e.g., Jina, BGE, Inf-Retriever).

---
#### ğŸ”¹ ğŸ¦™ Llama-3.2-3B-Instruct Series
- **Llama-3.2-3B-Instruct + Jina-Embeddings-v2-Base-EN**  
  [ğŸ¤— Model Card]()  
- **Llama-3.2-3B-Instruct + BGE-M3**  
  [ğŸ¤— Model Card](https://huggingface.co/Jackson0018/Llama-3.2-3B-Instruct_BGE)
- **Llama-3.2-3B-Instruct + Inf-Retriever-v1-1.5B**  
  [ğŸ¤— Model Card](https://huggingface.co/Jackson0018/Llama-3.2-3B-Instruct_INFV)

---
#### ğŸ”¹ ğŸ‰ Qwen-2.5-3B-Instruct Series
- **Qwen-2.5-3B-Instruct + Jina-Embeddings-v2-Base-EN**  
  [ğŸ¤— Model Card]()  
- **Qwen-2.5-3B-Instruct + BGE-M3**  
  [ğŸ¤— Model Card](https://huggingface.co/Jackson0018/Qwen2.5-3B-Instruct_BGE)
- **Qwen-2.5-3B-Instruct + Inf-Retriever-v1-1.5B**  
  [ğŸ¤— Model Card](https://huggingface.co/Jackson0018/Qwen2.5-3B-Instruct_INFV)

```bash
python download_query_optimizers.py
```

### Run Evaluation using Llama-based DPO-trained Query Optimizers (only for SciFullBench)
```bash
bash Scripts/deploy_vllm_method_agent.sh
bash Scripts/deploy_vllm_experiment_agent.sh
bash Scripts/deploy_vllm_research_question_agent.sh

bash Scripts/inference_QoA_parallel_ai.sh
```

### Run Evaluation using QWEN-based DPO-trained Query Optimizers (only for SciFullBench)
```bash
bash Scripts/deploy_vllm_method_agent_QWEN.sh
bash Scripts/deploy_vllm_experiment_agent_QWEN.sh
bash Scripts/deploy_vllm_research_question_agent_QWEN.sh

bash Scripts/inference_QoA_parallel_ai.sh
```

### Run Evaluation using untrained Query Optimizers on SciFullBench
```bash
bash Scripts/inference_QoA_parallel_ai.sh
```

### Run Evaluation using untrained Query Optimizers for PatentFullBench
```bash
bash Scripts/inference_QoA_parallel_patents.sh
```

### How to reproduce results using SciMult
- To reproduce retrieval performance using SciMult embedding model, you must create separate conda environment following the instructions provided in the below repository
- **SciMult Repository** [SciMult](https://github.com/yuzhimanhua/SciMult)

```bash
bash Scripts/inference_QoA_parallel_ai_SciMult.sh
```

